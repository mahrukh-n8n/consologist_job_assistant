---
phase: 02-scraping-engine
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/content/detail-scraper.js
autonomous: true

must_haves:
  truths:
    - "Calling scrapeDetailPage() on a live Upwork job detail page returns a single object with all 15 fields populated"
    - "No field name deviates from the reference project spelling or casing"
    - "Fields with missing DOM data return null (never undefined or omitted)"
    - "skills is always an array, even when empty"
    - "client_payment_verified is always a boolean"
    - "job_id is extracted from the current page URL, not hardcoded"
  artifacts:
    - path: "src/content/detail-scraper.js"
      provides: "scrapeDetailPage() — reads job detail page DOM and returns full 15-field job object"
      exports: ["scrapeDetailPage"]
  key_links:
    - from: "src/content/detail-scraper.js"
      to: "src/utils/job-parser.js"
      via: "import { extractJobId }"
      pattern: "extractJobId"
    - from: "src/content/upwork-content.js"
      to: "src/content/detail-scraper.js"
      via: "import { scrapeDetailPage }"
      pattern: "scrapeDetailPage"
---

<objective>
Build the job detail page scraper that extracts all 15 reference-project fields from a single Upwork job posting page.

Purpose: Phase 3 requires full job objects for webhook push and CSV export. The search scraper only returns 3 fields; this scraper completes the dataset from detail pages. Also used in Phase 4 proposal workflow.
Output: src/content/detail-scraper.js
</objective>

<execution_context>
@C:/Users/Glorvax/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Glorvax/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-scraping-engine/02-01-SUMMARY.md
</context>

## Field Name Mapping

All 15 output field names are case-sensitive and must match the reference project exactly. Every field must be present in the returned object; use null for fields not found in DOM.

| Output Field | Type | DOM Source Strategy |
|---|---|---|
| `job_id` | string | Extract from `window.location.href` using extractJobId() |
| `title` | string | `[data-test="job-title"] h1`, `h1.job-title`, `h1` |
| `url` | string | `window.location.href` |
| `description` | string | `[data-test="description"] p`, `.description p`, `.job-description` — join all `<p>` text |
| `budget` | string | `[data-test="budget"]`, `.budget`, text containing `$` near budget label |
| `payment_type` | string | `"fixed"` or `"hourly"` — detect from budget text or `[data-test="job-type"]` |
| `skills` | string[] | `[data-test="skill-badge"]`, `.skill-badge`, `[data-test="skills"] .badge` — map to text array |
| `experience_level` | string | `[data-test="experience-level"]`, `.experience-level`, text near "Experience Level" label |
| `project_duration` | string | `[data-test="duration"]`, `.duration`, text near "Duration" label |
| `posted_date` | string | `[data-test="posted-on"]`, `time[datetime]` → use datetime attr, `.posted-on` |
| `proposals_count` | string | `[data-test="proposals"]`, `.proposals-count`, text near "Proposals" label |
| `client_payment_verified` | boolean | Presence of `[data-test="payment-verified"]` icon or `.payment-verified` — true if element exists |
| `client_location` | string | `[data-test="client-location"]`, `.client-location`, text near "Location" label |
| `client_rating` | string | `[data-test="client-rating"]`, `.client-rating .rating`, star rating text/aria-label |
| `client_total_spent` | string | `[data-test="total-spent"]`, `.total-spent`, text containing `$` near "Total spent" label |

<tasks>

<task type="auto">
  <name>Task 1: Detail page scraper with all 15 fields and fallback selectors</name>
  <files>src/content/detail-scraper.js</files>
  <action>
Create src/content/detail-scraper.js. This runs inside a content script context (full DOM access). Import extractJobId from 02-01's utility.

**Helper pattern — use throughout to avoid repetition:**

```js
/**
 * Tries a list of CSS selectors in order, returns the first match's trimmed textContent.
 * Returns null if none match.
 */
function firstText(selectors) {
  for (const sel of selectors) {
    const el = document.querySelector(sel);
    if (el && el.textContent.trim()) return el.textContent.trim();
  }
  return null;
}
```

**Full implementation:**

```js
import { extractJobId } from '../utils/job-parser.js';

function firstText(selectors) {
  for (const sel of selectors) {
    const el = document.querySelector(sel);
    if (el && el.textContent.trim()) return el.textContent.trim();
  }
  return null;
}

/**
 * Scrapes the current Upwork job detail page.
 * Returns an object with all 15 reference-project fields.
 * Missing fields are null, never undefined.
 *
 * @returns {Object} Full job object with reference-project field names
 */
export function scrapeDetailPage() {
  const pageUrl = window.location.href;
  const job_id = extractJobId(pageUrl);

  // title
  const title = firstText([
    '[data-test="job-title"] h1',
    'h1.job-title',
    'h1',
  ]);

  // description — join all paragraph text inside the description container
  let description = null;
  const descSelectors = [
    '[data-test="description"]',
    '.description',
    '.job-description',
  ];
  for (const sel of descSelectors) {
    const container = document.querySelector(sel);
    if (container) {
      const paragraphs = Array.from(container.querySelectorAll('p'));
      const text = paragraphs.length
        ? paragraphs.map(p => p.textContent.trim()).filter(Boolean).join('\n\n')
        : container.textContent.trim();
      if (text) { description = text; break; }
    }
  }

  // budget
  const budget = firstText([
    '[data-test="budget"]',
    '[data-test="hourly-rate"]',
    '.budget',
    '.hourly-rate',
  ]);

  // payment_type — detect "hourly" vs "fixed" from page context
  let payment_type = null;
  const jobTypeEl = document.querySelector('[data-test="job-type"]');
  if (jobTypeEl) {
    const raw = jobTypeEl.textContent.toLowerCase();
    payment_type = raw.includes('hourly') ? 'hourly' : 'fixed';
  } else if (budget) {
    payment_type = budget.toLowerCase().includes('/hr') ? 'hourly' : 'fixed';
  }

  // skills — collect all badge elements as text array
  const skillSelectors = [
    '[data-test="skill-badge"]',
    '.skill-badge',
    '[data-test="skills"] .badge',
    '.skills-list .badge',
  ];
  let skills = [];
  for (const sel of skillSelectors) {
    const els = document.querySelectorAll(sel);
    if (els.length > 0) {
      skills = Array.from(els).map(el => el.textContent.trim()).filter(Boolean);
      break;
    }
  }

  // experience_level
  const experience_level = firstText([
    '[data-test="experience-level"]',
    '.experience-level',
    '[data-test="contractor-tier"]',
  ]);

  // project_duration
  const project_duration = firstText([
    '[data-test="duration"]',
    '[data-test="project-duration"]',
    '.duration',
    '.project-duration',
  ]);

  // posted_date — prefer datetime attribute for machine-readable value
  let posted_date = null;
  const timeEl = document.querySelector('[data-test="posted-on"] time, time[datetime]');
  if (timeEl) {
    posted_date = timeEl.getAttribute('datetime') || timeEl.textContent.trim() || null;
  } else {
    posted_date = firstText(['[data-test="posted-on"]', '.posted-on', '.posted-date']);
  }

  // proposals_count
  const proposals_count = firstText([
    '[data-test="proposals"]',
    '.proposals-count',
    '[data-test="proposals-count"]',
  ]);

  // client_payment_verified — boolean presence check
  const paymentVerifiedEl = document.querySelector(
    '[data-test="payment-verified"], .payment-verified, [data-test="payment-status-verified"]'
  );
  const client_payment_verified = paymentVerifiedEl !== null;

  // client_location
  const client_location = firstText([
    '[data-test="client-location"]',
    '.client-location',
    '[data-test="location"]',
  ]);

  // client_rating
  const client_rating = firstText([
    '[data-test="client-rating"] .rating',
    '[data-test="client-rating"]',
    '.client-rating .rating',
    '.client-rating',
  ]);

  // client_total_spent
  const client_total_spent = firstText([
    '[data-test="total-spent"]',
    '.total-spent',
    '[data-test="client-total-spent"]',
  ]);

  const job = {
    job_id,
    title,
    url: pageUrl,
    description,
    budget,
    payment_type,
    skills,
    experience_level,
    project_duration,
    posted_date,
    proposals_count,
    client_payment_verified,
    client_location,
    client_rating,
    client_total_spent,
  };

  console.debug('[upwork-ext] detail scrape:', job_id, '— fields populated:', Object.values(job).filter(v => v !== null && v !== false).length, '/ 15');

  return job;
}
```

Important constraints:
- Field order in the returned object must match the table above (job_id first, client_total_spent last)
- skills is always an array (empty array [] when none found, never null)
- client_payment_verified is always boolean (never string)
- All other fields are string | null
- No field may be undefined — every key must be present in the returned object
  </action>
  <verify>Navigate to a live Upwork job detail page (https://www.upwork.com/jobs/*). Open DevTools console. Call scrapeDetailPage(). Confirm: (1) returned object has exactly 15 keys, (2) job_id is non-null, (3) skills is an array, (4) client_payment_verified is boolean, (5) no value is undefined.</verify>
  <done>scrapeDetailPage() returns an object with all 15 keys matching reference field names exactly. job_id extracted from current URL. skills is []. client_payment_verified is boolean. Fields without DOM matches are null, not undefined or missing.</done>
</task>

</tasks>

<verification>
1. Navigate to a live Upwork job detail URL, e.g. `https://www.upwork.com/jobs/Some-Job_~abc123/`
2. Confirm content script is injected (check console for extension logs)
3. Run `scrapeDetailPage()` in console
4. Verify returned object keys match exactly: job_id, title, url, description, budget, payment_type, skills, experience_level, project_duration, posted_date, proposals_count, client_payment_verified, client_location, client_rating, client_total_spent
5. Verify `typeof result.client_payment_verified === 'boolean'`
6. Verify `Array.isArray(result.skills) === true`
7. Verify no value is `undefined` — `Object.values(result).includes(undefined)` returns false
</verification>

<success_criteria>
- src/content/detail-scraper.js exists and exports scrapeDetailPage
- Returned object has exactly these 15 keys in snake_case: job_id, title, url, description, budget, payment_type, skills, experience_level, project_duration, posted_date, proposals_count, client_payment_verified, client_location, client_rating, client_total_spent
- skills is always an array
- client_payment_verified is always boolean
- All other fields are string or null, never undefined
- Multiple fallback selectors implemented for each field
- Field names are byte-for-byte identical to reference project (critical for n8n webhook compatibility)
</success_criteria>

<output>
After completion, create `.planning/phases/02-scraping-engine/02-02-SUMMARY.md` following the summary template.
</output>
